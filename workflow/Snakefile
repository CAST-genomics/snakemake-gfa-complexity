# Main entrypoint of the workflow. 
# Please follow the best practices: 
# https://snakemake.readthedocs.io/en/stable/snakefiles/best_practices.html,
# in particular regarding the standardized folder structure mentioned there. 

"""
Usage:
snakemake --configfile profile/config.yaml -C trait=[my_trait] <-n (dry run)>

snakemake --cluster --configfile config/config.yaml -C trait=PASS_Schizophrenia_Pardinas2018 -n 

snakemake --configfile config/config.yaml -C trait=PASS_Schizophrenia_Pardinas2018 \
    --cores all
"""

import os

TRAIT = config["trait"]
SUMSTAT_DIR = "/expanse/lustre/projects/ddp412/tamariutabartell/sumstats/"
OUT_DIR = "output/" + TRAIT 
OUT_HEAD = OUT_DIR + "/" + TRAIT

print(OUT_DIR)
print(OUT_HEAD)
print(os.getcwd())

rule all:
    input:
        OUT_HEAD + ".scores"

# Convert to plink.assoc file format
# https://www.cog-genomics.org/plink/1.9/formats#assoc
rule sumstats_to_plink:
    input:
        SUMSTAT_DIR + TRAIT + ".sumstats"
    output:
        OUT_HEAD + ".assoc"
    script:
        "scripts/sumstats_to_plinklinear.py"

# Sort plink.assoc files so that most significant hits are at the top
rule sort_plink:
    input:
        OUT_HEAD + ".assoc"
    output:
        OUT_HEAD + ".assoc.sorted"
    shell:
        """
        (head -n 1 {input} \
        && tail -n +2 {input} \
        | sort -t$'\t' -k7,7 -nr ) > {output}
        """

# Convert plink.assoc.sorted files to bed files
rule plink_to_bed:
    input:
        OUT_HEAD + ".assoc.sorted"
    output:
        OUT_HEAD + ".sig.filtered.bed"
    script:
        "scripts/plinklinear_to_bed.py"

# Subset subgraph gfa files from pangenome graph using bed files
rule bed_to_subgraphs:
    input:
        OUT_HEAD + ".sig.filtered.bed"
    output:
        OUT_DIR + "/subset_graphs/.success",
        OUT_DIR + "/subset_graphs/*.gfa"
    script:
        "scripts/bed_to_gfas.py"

# Generate complextity scores in tmp files from subgraphs
rule subgraph_to_complexity:
    input:  
        OUT_DIR + "/subset_graphs/{range}.gfa",
        OUT_DIR + "/subset_graphs/.success"
    output:
        OUT_DIR + "/scores/{range}.processed", 
    resources:
        time = 600,
        ntasks = 1
    script:
        "scripts/gfa_to_complexity.py"

# Concat complexities into a single output file and elminate tmp files
rule concat_complexties:
    input:
        files = OUT_DIR + "/scores/*.processed"
    output:
        OUT_HEAD + ".scores"
    shell:
        """
        touch {output}
        cat {input} >> {output}
        rm {input}
        """